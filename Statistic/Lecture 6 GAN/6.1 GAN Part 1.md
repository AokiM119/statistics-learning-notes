# Network as Generator

Input (x) + Simple Distribution (z) -> Network -> Output (y)

z是从一个（简单）分布里sample出来的，we know its formulation so we can sample from it.

![400](6_1_NetworkAsGenerator.png)
Sample的值不同，得到的输出就不一样。

为什么我们需要generator？为什么输出有的时候需要是一个分布？
“有两种可能性的数据，同时存在训练资料里”，此时需要让机器的输出是带“机率”的。

![400](6_2_DistributedOutput.png)
- Especially for tasks need "creativity" - 输出的值有多种的“可能性”
- The same input could result in different output

Generative Models
生成式的模型中比较知名的一个就是GAN（Generative Adversarial Network，对抗式生成模型）。

# GAN

Unconditional Generation
- Input (x) 
	- Unconditional generator没有输入x
- Simple Distribution (z) 
	- 通常选择低维的向量，服从正态分布
	- Low-dim vector, ~normal distribution
- Output (y)
	- Generator需要对z进行升维。
	- Output z is of complex distribution, and of high-dim vector.
![400](6_3_AnimeFaceGen.png)


在GAN里面需要额外训练的模块：Discriminator

## Discriminator
![400](6_4_Discriminator.png)
拿图片作为输入，输出是一个数值。Discriminator本身也是一个neural network（架构完全可以由自己设计）.
输出数值越大，说明输入越像是一个真的二次元头像。

## Basic Idea of GAN
GAN进行生成的过程：
第一代的Generator - 参数完全随机 - 第一代的Discriminator进行评分
![400](6_5_GANStructure.png)
上述的是生成过程还是训练过程？

### Algorithm
- Initialize generator and discriminator
- In each training iteration:
	- **Step 1: fix generator G, and update discriminator D.**
		![300](6_6_RandomG.png)
		准备好二次元图库，sample出一些真正的二次元头像，将这些头像与G产生的一批generated objects一起去训练判别器（注意，这里不是比对，而很有可能是以labelled information去做判别，对于判别器的神经网络来说可能是分类/回归问题）。
		![300](6_7_AnimeDatabase.png)
		图库的全标1，第一批generated的全部标注为0
		![300](6_8_LabelDatabase.png)
		Discriminator learns to assign high scores to real objects and low scores to generated object.
	- **Step 2: Fix discriminator D, and update generator G.**
		Generator learns to fool the discriminator.
		![300](6_9_TrainGenerator.png)
		训练G的时候，可以将中途输出的图片当作一层hidden layer，把整个large network进行backpropagation，但是不修改后面D中的参数。
		![300](6_10_LargeNetwork.png)
训练GAN的时候，它还能够学到处理interpolated的向量。